{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import dask.dataframe as dd\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow.python.client import device_lib\n",
    "from matplotlib import font_manager, rc, dates\n",
    "font_path = \"C:/Windows/Fonts/NGULIM.TTF\"\n",
    "font = font_manager.FontProperties(fname=font_path).get_name()\n",
    "rc('font', family=font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0\n",
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 5094453291372257098\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 3622658048\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 7108201075859466735\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\"\n",
      "xla_global_id: 416903419\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward_co2(co2):\n",
    "    reward = np.exp(-((co2-900)**2)/(2*350**2))\n",
    "    return reward\n",
    "\n",
    "\n",
    "def reward_heat(temp):\n",
    "    reward = np.exp(-((temp-29)**2)/(2*2**2))\n",
    "    return reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 학습용 데이터셋 준비(솜사탕)\n",
    "* 거실만사용\n",
    "* 환기, 보일러작동 2개로 멀티에이전트 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Go\\OneDrive - UOS\\allrepos\\multi_agent_awac\n",
      "['남부', '동화나라', '소리엘', '솜사탕', '예나']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Go\\AppData\\Local\\Temp\\ipykernel_16648\\3654965324.py:33: FutureWarning: `include_start` and `include_end` are deprecated in favour of `inclusive`.\n",
      "  data.loc[data.between_time('12:00:00', '18:00:00',include_end=False).index,['vent']] = 1\n",
      "C:\\Users\\Go\\AppData\\Local\\Temp\\ipykernel_16648\\3654965324.py:34: FutureWarning: `include_start` and `include_end` are deprecated in favour of `inclusive`.\n",
      "  data.loc[data.between_time('9:00:00', '16:00:00',include_end=False).index,['people']] = 1\n",
      "C:\\Users\\Go\\AppData\\Local\\Temp\\ipykernel_16648\\3654965324.py:35: FutureWarning: `include_start` and `include_end` are deprecated in favour of `inclusive`.\n",
      "  data.loc[data.between_time('9:00:00', '16:00:00',include_end=False).index,['heat']] = 1\n"
     ]
    }
   ],
   "source": [
    "## 불러오기 ##\n",
    "path = os.getcwd()\n",
    "site_list = sorted(glob(os.path.join(path,\"data\",\"sensing_data\",\"*\")))\n",
    "site_list = list(map(os.path.basename,site_list))\n",
    "print(path)\n",
    "print(site_list)\n",
    "site = \"솜사탕\"\n",
    "time_mean = \"5T\"\n",
    "csv_by_site_det = []\n",
    "\n",
    "\n",
    "structure = sorted(glob(os.path.join(path,\"data\",\"sensing_data\",site,'*')))\n",
    "structure = list(map(os.path.basename,structure))\n",
    "for j in structure:\n",
    "        temp_data = dd.read_csv(os.path.join(path,\"data\",\"sensing_data\",site,j),encoding='cp949').compute()\n",
    "        temp_data['T/D'] = pd.to_datetime(temp_data['T/D'])\n",
    "       \n",
    "        temp_data.set_index('T/D',inplace=True)\n",
    "        temp_data = temp_data.resample(time_mean,).mean()\n",
    "        temp_data['site_details'] = j\n",
    "        csv_by_site_det.append(temp_data)\n",
    "\n",
    "data = pd.concat(csv_by_site_det)\n",
    "data.columns = ['index','temp','hum','pm1','pm2.5','pm4','pm10','co2','tvoc','site_details']\n",
    "data = data[['temp','hum','pm1','pm2.5','pm4','pm10','co2','tvoc','site_details']]\n",
    "## 라벨링 ##\n",
    "\n",
    "data['vent'] = 0\n",
    "data['people'] = 0\n",
    "data['heat'] = 0\n",
    "\n",
    "\n",
    "data.loc[data.between_time('12:00:00', '18:00:00',include_end=False).index,['vent']] = 1\n",
    "data.loc[data.between_time('9:00:00', '16:00:00',include_end=False).index,['people']] = 1\n",
    "data.loc[data.between_time('9:00:00', '16:00:00',include_end=False).index,['heat']] = 1\n",
    "\n",
    "#0부터 월요일\n",
    "data.loc[data[data.index.dayofweek == 5].index,['vent']] = 0\n",
    "data.loc[data[data.index.dayofweek == 5].index,['people']] = 0\n",
    "data.loc[data[data.index.dayofweek == 5].index,['heat']] = 0\n",
    "\n",
    "data.loc[data[data.index.dayofweek == 6].index,['vent']] = 0\n",
    "data.loc[data[data.index.dayofweek == 6].index,['people']] = 0\n",
    "data.loc[data[data.index.dayofweek == 6].index,['heat']] = 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Go\\AppData\\Local\\Temp\\ipykernel_16648\\1764209178.py:15: FutureWarning: `include_start` and `include_end` are deprecated in favour of `inclusive`.\n",
      "  dataset.loc[dataset.between_time('00:00:00', '00:05:00',include_end=False).index,['done']] = True\n",
      "C:\\Users\\Go\\AppData\\Local\\Temp\\ipykernel_16648\\1764209178.py:15: FutureWarning: `include_start` and `include_end` are deprecated in favour of `inclusive`.\n",
      "  dataset.loc[dataset.between_time('00:00:00', '00:05:00',include_end=False).index,['done']] = True\n",
      "C:\\Users\\Go\\AppData\\Local\\Temp\\ipykernel_16648\\1764209178.py:15: FutureWarning: `include_start` and `include_end` are deprecated in favour of `inclusive`.\n",
      "  dataset.loc[dataset.between_time('00:00:00', '00:05:00',include_end=False).index,['done']] = True\n",
      "C:\\Users\\Go\\AppData\\Local\\Temp\\ipykernel_16648\\1764209178.py:15: FutureWarning: `include_start` and `include_end` are deprecated in favour of `inclusive`.\n",
      "  dataset.loc[dataset.between_time('00:00:00', '00:05:00',include_end=False).index,['done']] = True\n",
      "C:\\Users\\Go\\AppData\\Local\\Temp\\ipykernel_16648\\1764209178.py:15: FutureWarning: `include_start` and `include_end` are deprecated in favour of `inclusive`.\n",
      "  dataset.loc[dataset.between_time('00:00:00', '00:05:00',include_end=False).index,['done']] = True\n",
      "C:\\Users\\Go\\AppData\\Local\\Temp\\ipykernel_16648\\1764209178.py:15: FutureWarning: `include_start` and `include_end` are deprecated in favour of `inclusive`.\n",
      "  dataset.loc[dataset.between_time('00:00:00', '00:05:00',include_end=False).index,['done']] = True\n"
     ]
    }
   ],
   "source": [
    "room_list = ['솜사탕_거실.csv', '솜사탕_방1.csv','솜사탕_방2.csv','솜사탕_방3.csv','솜사탕_방4.csv','솜사탕_부엌.csv',]\n",
    "data_by_room = {}\n",
    "data_room = data.loc[:,['temp','co2','site_details','vent','heat','people']]\n",
    "\n",
    "for i in room_list:\n",
    "    room_name = i\n",
    "    dataset = data_room.loc[data_room.site_details == room_name,:][['temp','co2','vent','heat','people']]\n",
    "\n",
    "    dataset.loc[:,'co2_t+1'] = dataset.loc[:,'co2'].shift(-1)\n",
    "    dataset.loc[:,'temp_t+1'] = dataset.loc[:,'temp'].shift(-1)\n",
    "    dataset.loc[:,'people_t+1'] = dataset.loc[:,'people'].shift(-1)\n",
    "    dataset.loc[:,'reward_co2'] = dataset.loc[:,'co2_t+1'].map(lambda x : reward_co2(x))\n",
    "    dataset.loc[:,'reward_heat'] = dataset.loc[:,'temp_t+1'].map(lambda x : reward_heat(x))\n",
    "    dataset.loc[:,'done'] = False\n",
    "    dataset.loc[dataset.between_time('00:00:00', '00:05:00',include_end=False).index,['done']] = True\n",
    "    dataset = dataset.iloc[:-1,:]\n",
    "    #데이터셋 추가\n",
    "    data_by_room[i] = dataset.loc[:,:][['co2','temp','people','co2_t+1','temp_t+1','people_t+1','reward_co2','reward_heat','vent','heat','done',]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 멀티에이전트 학습용 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dense model 만드는 함수\n",
    "def make_dense_model(hidden_structure,input_shape,act_function,output_shape):\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    \n",
    "    for i, val in enumerate(hidden_structure):\n",
    "        n_percep = val \n",
    "        if i == 0:\n",
    "            x = keras.layers.Dense(n_percep, activation= act_function)(inputs)\n",
    "\n",
    "        elif  i != 0 and i != len(hidden_structure)-1:\n",
    "            x = keras.layers.Dense(n_percep, activation= act_function)(x)\n",
    "\n",
    "        elif  i == len(hidden_structure)-1:\n",
    "            x = keras.layers.Dense(n_percep,activation= act_function)(x)\n",
    "    x = keras.layers.Dense(output_shape)(x)\n",
    "\n",
    "    dense_model = tf.keras.Model(inputs=inputs, outputs=x)\n",
    "    return dense_model\n",
    "\n",
    "# multi_agent structure 만드는 함수\n",
    "def build_structure(agent_num, hidden_structure,input_shape,act_function,output_shape):\n",
    "    actor_list = []\n",
    "    critic_qnet_list = []\n",
    "    critic_qnet_target_list = []\n",
    "    for i in range(agent_num):\n",
    "        actor_list.append(make_dense_model(hidden_structure,input_shape,act_function,output_shape))\n",
    "        critic_qnet_list.append(make_dense_model(hidden_structure,input_shape,act_function,output_shape))\n",
    "        critic_qnet_target_list.append(make_dense_model(hidden_structure,input_shape,act_function,output_shape))\n",
    "    return actor_list, critic_qnet_list, critic_qnet_target_list\n",
    "\n",
    "\n",
    "def get_action(actor,state, num_samples: int = 3):\n",
    "    logit_sam = actor(state)\n",
    "    m = tfp.distributions.Categorical(logits = logit_sam)\n",
    "    return tf.reshape(m.sample(num_samples),[-1,num_samples])\n",
    "\n",
    "def get_mean_qsa(qs,sampled_as):\n",
    "    \n",
    "    mean_q = tf.concat([tf.reshape(tf.gather(qs[i],sampled_as[i], axis=0),[1,-1]) for i in range(len(qs))],axis=0)\n",
    "    mean_q = tf.math.reduce_mean(mean_q,axis=1,keepdims=True)\n",
    "    return mean_q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 학습데이터셋 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "co2            0\n",
      "temp           0\n",
      "people         0\n",
      "co2_t+1        0\n",
      "temp_t+1       0\n",
      "people_t+1     0\n",
      "reward_co2     0\n",
      "reward_heat    0\n",
      "vent           0\n",
      "heat           0\n",
      "done           0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(TensorSpec(shape=(3,), dtype=tf.float32, name=None),\n",
       " TensorSpec(shape=(3,), dtype=tf.float32, name=None),\n",
       " ((TensorSpec(shape=(1,), dtype=tf.int64, name=None),\n",
       "   TensorSpec(shape=(1,), dtype=tf.float32, name=None)),\n",
       "  (TensorSpec(shape=(1,), dtype=tf.int64, name=None),\n",
       "   TensorSpec(shape=(1,), dtype=tf.float32, name=None))),\n",
       " TensorSpec(shape=(1,), dtype=tf.float32, name=None))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "room_sync_list = ['솜사탕_거실.csv']\n",
    "# room_sync_list = ['솜사탕_거실.csv', '솜사탕_거실.csv', '솜사탕_거실.csv', '솜사탕_거실.csv']\n",
    "# room_sync_list = ['솜사탕_거실.csv', '솜사탕_방2.csv']\n",
    "\n",
    "s = []\n",
    "ns = []\n",
    "a_list = []\n",
    "r_list = []\n",
    "\n",
    "start_date = '2022-01-04'\n",
    "end_date = '2022-01-27'\n",
    "\n",
    "len_list = []\n",
    "for i in room_sync_list:\n",
    "    temp_data = data_by_room[i].loc[start_date:end_date]\n",
    "    len_notna = len(temp_data.dropna())\n",
    "    len_list.append(len_notna)\n",
    "max_na_room = room_sync_list[np.argmin(len_list)]\n",
    "row_ind = data_by_room[max_na_room].loc[start_date:end_date].dropna().index\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "temp_data = data_by_room[i].loc[row_ind]\n",
    "\n",
    "s.append(tf.convert_to_tensor(temp_data.values[:,[0,1,2],],dtype=tf.float32))\n",
    "ns.append(tf.convert_to_tensor(temp_data.values[:,[3,4,5],],dtype=tf.float32))\n",
    "\n",
    "a_list.append(tf.convert_to_tensor(temp_data.values[:,[6],],dtype=tf.int64))\n",
    "a_list.append(tf.convert_to_tensor(temp_data.values[:,[7],],dtype=tf.int64))\n",
    "\n",
    "\n",
    "r_list.append(tf.convert_to_tensor(temp_data.values[:,[8],],dtype=tf.float32))\n",
    "r_list.append(tf.convert_to_tensor(temp_data.values[:,[9],],dtype=tf.float32))\n",
    "\n",
    "print(temp_data.isna().sum())\n",
    "#정규화 레이어\n",
    "layer = tf.keras.layers.Normalization(axis=1)\n",
    "layer.adapt(s[0])\n",
    "\n",
    "#데이터셋 제작\n",
    "s_dataset = tf.data.Dataset.from_tensor_slices(layer(s[0]))\n",
    "ns_dataset = tf.data.Dataset.from_tensor_slices(layer(ns[0]))\n",
    "\n",
    "a1_dataset = tf.data.Dataset.from_tensor_slices(a_list[0])\n",
    "a2_dataset = tf.data.Dataset.from_tensor_slices(a_list[1])\n",
    "\n",
    "r1_dataset = tf.data.Dataset.from_tensor_slices(r_list[0])\n",
    "r2_dataset = tf.data.Dataset.from_tensor_slices(r_list[1])\n",
    "\n",
    "done_dataset = tf.data.Dataset.from_tensor_slices(tf.convert_to_tensor(data_by_room[i].loc[start_date:end_date].values[:,[10]],dtype=tf.float32))\n",
    "\n",
    "train_dataset = tf.data.Dataset.zip((s_dataset, ns_dataset, ((a1_dataset,r1_dataset),(a2_dataset,r2_dataset),),done_dataset))\n",
    "train_dataset.element_spec\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-run- [1]/[10]\n",
      "-run- [2]/[10]\n",
      "-run- [3]/[10]\n",
      "-run- [4]/[10]\n",
      "-run- [5]/[10]\n",
      "-run- [6]/[10]\n",
      "-run- [7]/[10]\n",
      "-run- [8]/[10]\n",
      "-run- [9]/[10]\n",
      "-run- [10]/[10]\n",
      "CPU times: total: 44.6 s\n",
      "Wall time: 44 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#################set params!################\n",
    "# params of multi_AWAC\n",
    "agent_num = 2\n",
    "state_len = 3\n",
    "hidden_structure= [64, 128, 256, 128, 64]\n",
    "input_shape= 3\n",
    "output_shape= 2\n",
    "act_function= 'relu'\n",
    "lam = 10\n",
    "optimizer= keras.optimizers.Adam(learning_rate=3 * 1e-5)\n",
    "gamma= 0.9\n",
    "tau = 0.1\n",
    "num_action_samples = 8\n",
    "loss_fun = tf.keras.losses.MeanSquaredError()\n",
    "\n",
    "# 학습 루프 관련\n",
    "batch_size = 256\n",
    "buffer_len = len(train_dataset)\n",
    "# n_train = 10\n",
    "n_run = 10\n",
    "############################################\n",
    "# 초기 모델 생성\n",
    "actor_list, critic_qnet_list, critic_qnet_target_list = build_structure(agent_num, hidden_structure,input_shape,act_function,output_shape)\n",
    "\n",
    "\n",
    "#배치셋 생성\n",
    "# batched_dataset = train_dataset.shuffle(buffer_size=buffer_len).batch(batch_size, drop_remainder=True)\n",
    "shuffled_dataset = train_dataset.shuffle(buffer_size=buffer_len)\n",
    "\n",
    "# 트레인 루프\n",
    "# for batch in batched_dataset.take(n_train):\n",
    "critic_loss = []\n",
    "actor_loss_1 = []\n",
    "actor_loss_2 = []\n",
    "\n",
    "count = 0\n",
    "for batch in shuffled_dataset.batch(batch_size).take(1).repeat(n_run):\n",
    "    count += 1\n",
    "    if count % 1 == 0:\n",
    "        print(f\"-run- [{count}]/[{n_run}]\")\n",
    "    \n",
    "\n",
    "    with tf.GradientTape() as t:\n",
    "        loss_list =[]\n",
    "        for j in range(agent_num):\n",
    "            ##데이터 \n",
    "            s = batch[0]\n",
    "            ns = batch[1]\n",
    "            a = batch[2][j][0]\n",
    "            r = batch[2][j][1]\n",
    "            done = batch[3]\n",
    "            ##에이전트\n",
    "            actor = actor_list[j]\n",
    "            critic_qnet = critic_qnet_list[j]\n",
    "            critic_qnet_target = critic_qnet_target_list[j]\n",
    "            ##로스 계산\n",
    "            qs = critic_qnet_target(ns)\n",
    "            sampled_as = get_action(actor,ns, num_action_samples)\n",
    "            mean_qsa = get_mean_qsa(qs,sampled_as)\n",
    "            q_target = r + gamma * mean_qsa * (1 - done)\n",
    "\n",
    "            # 식 3에서 봤던 것처럼 mse형태로 로스함수 설정\n",
    "            q_val = tf.concat([tf.reshape(tf.gather(critic_qnet(s)[k],a[k],axis=0),[-1,1]) for k in range(len(s))],axis=0)\n",
    "            loss = loss_fun(q_val, q_target)\n",
    "            loss_list.append(loss)\n",
    "        joint_loss = tf.math.reduce_mean(loss_list, axis=None, keepdims=False, name=None)\n",
    "        \n",
    "        critic_loss.append(joint_loss)\n",
    "\n",
    "    critic_qnet_weight_list = [critic_qnet_list[p].trainable_variables for p in range(agent_num)]\n",
    "    critic_qnet_target_weight_list = [critic_qnet_target_list[p].trainable_variables for p in range(agent_num)]\n",
    "    grads = t.gradient(joint_loss, critic_qnet_weight_list)\n",
    "\n",
    "    for q in range(agent_num):\n",
    "        # qnet 업데이트\n",
    "        qnet_weights = critic_qnet_weight_list[q]\n",
    "        qnet_target_weights = critic_qnet_target_weight_list[q]\n",
    "        grad = grads[q]\n",
    "\n",
    "        optimizer.apply_gradients(zip(grad, qnet_weights))\n",
    "        # target net 업데이트\n",
    "        new_target_weights = []\n",
    "        for p, target_weights in enumerate(qnet_target_weights):\n",
    "            qnet_weights_s = qnet_weights[p]\n",
    "            updated_target_weights_s = target_weights*(1 - tau) + qnet_weights_s*tau\n",
    "            new_target_weights.append(updated_target_weights_s)\n",
    "        critic_qnet_target_list[q].set_weights(new_target_weights)\n",
    "\n",
    "        #타겟네트워크까지 업데이트한 후 actor net 업데이트\n",
    "        with tf.GradientTape() as tp:\n",
    "            # log_probability 계산\n",
    "            logits = actor_list[q](s)\n",
    "            m = tfp.distributions.Categorical(logits = logits)\n",
    "            log_prob = tf.reshape(m.log_prob(a.numpy().squeeze()),[-1,1])\n",
    "\n",
    "            #가중치항 계산\n",
    "            qs = critic_qnet_target_list[q](s)\n",
    "            action_probs = tf.nn.softmax(logits, axis=None, name=None)\n",
    "            vs = tf.math.reduce_sum((qs * action_probs),axis=1, keepdims=True, name=None)\n",
    "            qas = tf.concat([tf.reshape(tf.gather(qs[k],a[k],axis=0),[-1,1]) for k in range(len(s))],axis=0)\n",
    "            adv = qas - vs\n",
    "            weight_term = tf.math.exp((1/lam*adv), name=None)\n",
    "            \n",
    "            \n",
    "\n",
    "            #loss\n",
    "            loss = tf.math.reduce_mean(log_prob * weight_term*-1)\n",
    "            \n",
    "            if q == 0 :\n",
    "                actor_loss_1.append(loss)\n",
    "            elif q == 1 :\n",
    "                actor_loss_2.append(loss)\n",
    "            \n",
    "        actor_grad = tp.gradient(loss, actor_list[q].trainable_variables)\n",
    "        \n",
    "        optimizer.apply_gradients(zip(actor_grad, actor_list[q].trainable_variables))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-run- [1]/[10]\n",
      "hear\n",
      "hear\n",
      "-run- [2]/[10]\n",
      "hear\n",
      "hear\n",
      "-run- [3]/[10]\n",
      "hear\n",
      "hear\n",
      "-run- [4]/[10]\n",
      "hear\n",
      "hear\n",
      "-run- [5]/[10]\n",
      "hear\n",
      "hear\n",
      "-run- [6]/[10]\n",
      "hear\n",
      "hear\n",
      "-run- [7]/[10]\n",
      "hear\n",
      "hear\n",
      "-run- [8]/[10]\n",
      "hear\n",
      "hear\n",
      "-run- [9]/[10]\n",
      "hear\n",
      "hear\n",
      "-run- [10]/[10]\n",
      "hear\n",
      "hear\n",
      "CPU times: total: 22.2 s\n",
      "Wall time: 21.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#################set params!################\n",
    "# params of multi_AWAC\n",
    "agent_num = 2\n",
    "state_len = 3\n",
    "hidden_structure= [64, 128, 256, 128, 64]\n",
    "input_shape= 3\n",
    "output_shape= 2\n",
    "act_function= 'relu'\n",
    "lam = 10\n",
    "optimizer= keras.optimizers.Adam(learning_rate=3 * 1e-5)\n",
    "gamma= 0.9\n",
    "tau = 0.1\n",
    "num_action_samples = 8\n",
    "loss_fun = tf.keras.losses.MeanSquaredError()\n",
    "\n",
    "# 학습 루프 관련\n",
    "batch_size = 256\n",
    "buffer_len = len(train_dataset)\n",
    "# n_train = 10\n",
    "n_run = 10\n",
    "############################################\n",
    "# 초기 모델 생성\n",
    "actor_list, critic_qnet_list, critic_qnet_target_list = build_structure(agent_num, hidden_structure,input_shape,act_function,output_shape)\n",
    "\n",
    "\n",
    "#배치셋 생성\n",
    "# batched_dataset = train_dataset.shuffle(buffer_size=buffer_len).batch(batch_size, drop_remainder=True)\n",
    "shuffled_dataset = train_dataset.shuffle(buffer_size=buffer_len)\n",
    "\n",
    "# 트레인 루프\n",
    "# for batch in batched_dataset.take(n_train):\n",
    "critic_loss = []\n",
    "actor_loss_1 = []\n",
    "actor_loss_2 = []\n",
    "\n",
    "actor = actor_list[0]\n",
    "critic_qnet = critic_qnet_list[0]\n",
    "critic_qnet_target = critic_qnet_target_list[0]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "count = 0\n",
    "for batch in shuffled_dataset.batch(batch_size).take(1).repeat(n_run):\n",
    "    count += 1\n",
    "    if count % 1 == 0:\n",
    "        print(f\"-run- [{count}]/[{n_run}]\")\n",
    "    \n",
    "\n",
    "    with tf.GradientTape() as t:\n",
    "        ##데이터 \n",
    "        s = batch[0]\n",
    "        ns = batch[1]\n",
    "        a = batch[2][0][0]\n",
    "        r = batch[2][0][1]\n",
    "        done = batch[3]\n",
    "        \n",
    "        ##로스 계산\n",
    "        qs = critic_qnet_target(ns)\n",
    "        sampled_as = get_action(actor,ns, num_action_samples)\n",
    "        mean_qsa = get_mean_qsa(qs,sampled_as)\n",
    "        q_target = r + gamma * mean_qsa * (1 - done)\n",
    "\n",
    "        # 식 3에서 봤던 것처럼 mse형태로 로스함수 설정\n",
    "        q_val = tf.concat([tf.reshape(tf.gather(critic_qnet(s)[k],a[k],axis=0),[-1,1]) for k in range(len(s))],axis=0)\n",
    "        loss = loss_fun(q_val, q_target)\n",
    "            \n",
    "    grads = t.gradient(loss, critic_qnet.trainable_variables)\n",
    "\n",
    "    for q in range(1):\n",
    "        # qnet 업데이트\n",
    "        # qnet_weights = critic_qnet_weight_list[q]\n",
    "        # qnet_target_weights = critic_qnet_target_weight_list[q]\n",
    "        # grad = grads[q]\n",
    "        print('hear')\n",
    "        optimizer.apply_gradients(zip(grads, critic_qnet.trainable_variables))\n",
    "        print('hear')\n",
    "        # target net 업데이트\n",
    "        new_target_weights = []\n",
    "        for p, target_weights in enumerate(critic_qnet_target.trainable_variables):\n",
    "            qnet_weights_s = critic_qnet.trainable_variables[p]\n",
    "            updated_target_weights_s = target_weights*(1 - tau) + qnet_weights_s*tau\n",
    "            new_target_weights.append(updated_target_weights_s)\n",
    "        critic_qnet_target.set_weights(new_target_weights)\n",
    "\n",
    "        #타겟네트워크까지 업데이트한 후 actor net 업데이트\n",
    "        with tf.GradientTape() as tp:\n",
    "            # log_probability 계산\n",
    "            logits = actor(s)\n",
    "            m = tfp.distributions.Categorical(logits = logits)\n",
    "            log_prob = tf.reshape(m.log_prob(a.numpy().squeeze()),[-1,1])\n",
    "\n",
    "            #가중치항 계산\n",
    "            qs = critic_qnet_target(s)\n",
    "            action_probs = tf.nn.softmax(logits, axis=None, name=None)\n",
    "            vs = tf.math.reduce_sum((qs * action_probs),axis=1, keepdims=True, name=None)\n",
    "            qas = tf.concat([tf.reshape(tf.gather(qs[k],a[k],axis=0),[-1,1]) for k in range(len(s))],axis=0)\n",
    "            adv = qas - vs\n",
    "            weight_term = tf.math.exp((1/lam*adv), name=None)\n",
    "            \n",
    "            \n",
    "\n",
    "            #loss\n",
    "            loss = tf.math.reduce_mean(log_prob * weight_term*-1)\n",
    "        actor_grad = tp.gradient(loss, actor.trainable_variables)\n",
    "        \n",
    "        optimizer.apply_gradients(zip(actor_grad, actor.trainable_variables))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d88f3696864b965ae6365a8a6eb5e7cd5f79d732e0c9aa87d8ba362b28afae3c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tensorgpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
